{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/round1_ijcai_18_train_20180301/round1_ijcai_18_train_20180301.txt', sep=' ') # 训练集数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('../Data/round1_ijcai_18_test_b_20180418.txt', sep=' ') # B测试集数据加载\n",
    "test_df = pd.read_csv('../Data/round1_ijcai_18_test_a_20180301/round1_ijcai_18_test_a_20180301.txt', sep=' ') # A测试集数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对训练集中部分特征值为NAN的样本进行删除\n",
    "df = df[df['shop_review_positive_rate']!=-1]\n",
    "df = df[df['shop_score_delivery']!=-1]\n",
    "df = df[df['shop_score_description']!=-1]\n",
    "df = df[df['shop_score_service']!=-1]\n",
    "df = df[df['item_brand_id']!=-1]\n",
    "df = df[df['item_city_id']!=-1]\n",
    "\n",
    "df = df.reset_index(drop=True) # 删除部分具有缺失值样本后重新更新数据集的index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 某些字段的取值范围可以进行缩放\n",
    " \n",
    "    user_age_level-1000\n",
    "    user_occupation_id-2000\n",
    "    user_star_level-3000\n",
    "    context_page_id-4000\n",
    "    shop_star_level-4999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataNormalization(data):\n",
    "    data.user_age_level = data.user_age_level.replace(-1,999)\n",
    "    data.user_age_level = data.user_age_level - 1000\n",
    "\n",
    "    data.user_occupation_id = data.user_occupation_id.replace(-1,1999)\n",
    "    data.user_occupation_id = data.user_occupation_id - 2000\n",
    "\n",
    "    data.user_star_level = data.user_star_level.replace(-1,2999)\n",
    "    data.user_star_level = data.user_star_level - 3000\n",
    "\n",
    "    data.context_page_id = data.context_page_id - 4000\n",
    "\n",
    "    data.shop_star_level = data.shop_star_level - 4999\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = dataNormalization(df)\n",
    "test_df = dataNormalization(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def occupationMap(value):\n",
    "    if value == 3 or value == -1:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "def userStarMap(value):\n",
    "    if value < 2:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "def ageMap(value):\n",
    "    if value < 3:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "def pageMap(value):\n",
    "    if value < 10:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "    \n",
    "def baseProcess(data):\n",
    "    data['user_gender'] = data['user_gender_id'].apply(lambda x: 1 if x==-1 else 2)\n",
    "    data['user_age'] = data['user_age_level'].apply(ageMap)\n",
    "    data['user_occupation'] = data['user_occupation_id'].apply(occupationMap)\n",
    "    data['user_star'] = data['user_star_level'].apply(userStarMap)\n",
    "    data['context_page'] = data['context_page_id'].apply(pageMap)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通过对平均交易量进行可视化操作，进行离散化操作\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualData(data, colName):\n",
    "    plt.figure()\n",
    "    x = data['is_trade'].groupby(data[colName]).mean().index\n",
    "    y = data['is_trade'].groupby(data[colName]).mean().get_values()\n",
    "    m = data['is_trade'].groupby(data[colName]).mean().median()\n",
    "    plt.plot(x,y)\n",
    "    plt.hlines(m,x.min(),x.max())\n",
    "#     plt.xlim(x.max()//100*100,x.max())\n",
    "\n",
    "\n",
    "visualData(df, 'shop_star_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataConvert(df):\n",
    "    df['len_item_category'] = df['item_category_list'].apply(lambda str1: len(str1.split(';')))\n",
    "    for i in range(3):\n",
    "        df['item_category_%d'%i] = df['item_category_list'].apply(lambda str1: int(str1.split(';')[i]) if len(str1.split(';'))>i else -1)\n",
    "    df = df.drop(['item_category_list'], 1)\n",
    "    \n",
    "    # 属性类别属性的出现顺序无规则且无序\n",
    "    df['len_item_property'] = df['item_property_list'].apply(lambda str1: len(np.unique(str1.split(';'))))\n",
    "    for i in range(5):\n",
    "        df['item_property_%d'%i] = df['item_property_list'].apply(lambda str1: int(np.unique(str1.split(';'))[i]) if len(np.unique(str1.split(';')))>i else -1)\n",
    "    df = df.drop(['item_property_list'], 1)\n",
    "    \n",
    "    df['len_predict_category_property'] = df['predict_category_property'].apply(lambda str1: len(str1.split(';')))\n",
    "    for i in range(10):\n",
    "        df['predict_category_property_%d'%i] = df['predict_category_property'].apply(lambda str1: int(str1.split(';')[i].split(':')[0]) \\\n",
    "                                                                                     if len(str1.split(';'))>i else -1)\n",
    "    df = df.drop(['predict_category_property'], 1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeStampConvert(df):\n",
    "    xShape = df.shape[0]\n",
    "    df['context_time_hour'] = [datetime.datetime.fromtimestamp(df['context_timestamp'][i]).hour for i in range(xShape)]\n",
    "    df['context_time_day'] = [datetime.datetime.fromtimestamp(df['context_timestamp'][i]).day for i in range(xShape)]\n",
    "    df['context_time_weekday'] = [datetime.datetime.fromtimestamp(df['context_timestamp'][i]).weekday() for i in range(xShape)]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 根据真实情景的时间段广告点击情况来划分时间区间\n",
    "def mapHour(hour):\n",
    "    if hour >=7 and hour <=12:\n",
    "        return 1\n",
    "    elif (hour >= 13 and hour <= 20):\n",
    "        return 2\n",
    "    return 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataProcess(data):\n",
    "    data = baseProcess(data)\n",
    "    data = dataConvert(data)\n",
    "    data = timeStampConvert(data)\n",
    "    data['context_time_hour_map'] = data['context_time_hour'].apply(mapHour)\n",
    "    return data\n",
    "   \n",
    "df = dataProcess(df)\n",
    "test_df = dataProcess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477334, 54)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../Output/a/train_step2_301.csv', index=False)\n",
    "test_df.to_csv('../Output/a/test_step2_301.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Output/a/train_step2_301.csv') # 预处理后的测试集数据加载\n",
    "test_df = pd.read_csv('../Output/a/test_step2_301.csv') # 预处理后的测试集数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477334, 54)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477334, 54)\n",
      "(477334, 59)\n"
     ]
    }
   ],
   "source": [
    "def tradeRateCalculate(data, test_data, cols=['item_id', 'shop_id','user_id','item_brand_id','item_city_id']):\n",
    "    dmin = data['context_time_day'].min()\n",
    "    dmax = test_data['context_time_day'].max()\n",
    "    for col in cols:\n",
    "        for day in range(dmin, dmax+1):\n",
    "            df_p1 = data[df.context_time_day==day-1]\n",
    "            df_p2 = data[df.context_time_day==day]\n",
    "            itemtrade = df_p1.groupby([col, 'context_time_day'],  as_index=False).agg({'is_trade':'sum','instance_id':'count'})\n",
    "            itemtrade[col+'_traderate'] = itemtrade.is_trade / itemtrade.instance_id\n",
    "            if day == dmin:\n",
    "                rdf = itemtrade\n",
    "            elif day == dmax:\n",
    "                test_data = pd.merge(test_data, itemtrade[[col, str(col)+'_traderate', 'context_time_day']], on=[col, 'context_time_day'],how='left').replace(np.nan, 0.0)\n",
    "            else:\n",
    "                rdf = pd.concat([rdf, itemtrade])\n",
    "        data = pd.merge(data, rdf[[col, str(col)+'_traderate', 'context_time_day']], on=[col, 'context_time_day'],how='left').replace(np.nan, 0.0)\n",
    "    return data, test_data\n",
    "\n",
    "print (df.shape)\n",
    "df, test_df = tradeRateCalculate(df, test_df)\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropCols(data):\n",
    "    return data.drop(['item_category_0'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataLabelEncoder(df):\n",
    "    df['item_category_1'] = pd.Categorical(df['item_category_1']).codes\n",
    "    df['item_category_2'] = pd.Categorical(df['item_category_2']).codes\n",
    "\n",
    "    df['item_property_0'] = pd.Categorical(df['item_property_0']).codes\n",
    "    df['item_property_1'] = pd.Categorical(df['item_property_1']).codes\n",
    "    df['item_property_2'] = pd.Categorical(df['item_property_2']).codes\n",
    "    df['item_property_3'] = pd.Categorical(df['item_property_3']).codes\n",
    "    df['item_property_4'] = pd.Categorical(df['item_property_4']).codes\n",
    "\n",
    "    df['predict_category_property_0'] = pd.Categorical(df['predict_category_property_0']).codes\n",
    "    df['predict_category_property_1'] = pd.Categorical(df['predict_category_property_1']).codes\n",
    "    df['predict_category_property_2'] = pd.Categorical(df['predict_category_property_2']).codes\n",
    "    df['predict_category_property_3'] = pd.Categorical(df['predict_category_property_3']).codes\n",
    "    df['predict_category_property_4'] = pd.Categorical(df['predict_category_property_4']).codes\n",
    "    df['predict_category_property_5'] = pd.Categorical(df['predict_category_property_5']).codes\n",
    "    df['predict_category_property_6'] = pd.Categorical(df['predict_category_property_6']).codes\n",
    "    df['predict_category_property_7'] = pd.Categorical(df['predict_category_property_7']).codes\n",
    "    df['predict_category_property_8'] = pd.Categorical(df['predict_category_property_8']).codes\n",
    "    df['predict_category_property_9'] = pd.Categorical(df['predict_category_property_9']).codes\n",
    "\n",
    "    df['shop_id'] = pd.Categorical(df['shop_id']).codes\n",
    "    df['item_brand_id'] = pd.Categorical(df['item_brand_id']).codes\n",
    "    df['item_city_id'] = pd.Categorical(df['item_city_id']).codes\n",
    "    df['user_id'] = pd.Categorical(df['user_id']).codes\n",
    "    df['item_id'] = pd.Categorical(df['item_id']).codes\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 连续值离散化 根据实际场景分段处理\n",
    "def reviewMap(score):\n",
    "    if score >= 0.98 :\n",
    "        return 3\n",
    "    elif score >= 0.965 :\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def serviceMap(score):\n",
    "    if (score > 0.945 and score <=0.995):\n",
    "        return 3\n",
    "    elif (score > 0.94 and score <= 0.945) or (score>0.995):\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def deliveryMap(score):\n",
    "    if (score > 0.945 and score <=0.995):\n",
    "        return 3\n",
    "    elif (score > 0.916 and score <= 0.945) or (score>0.995):\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def dspMap(score):\n",
    "    if (score >= 0.94 and score <=0.996):\n",
    "        return 3\n",
    "    elif (score > 0.905 and score < 0.94) or (score>0.996):\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def constantMap(data):\n",
    "    data['shop_review_positive_map'] = data['shop_review_positive_rate'].apply(reviewMap)\n",
    "    data['shop_map_service'] = data['shop_score_service'].apply(serviceMap)\n",
    "    data['shop_map_delivery'] = data['shop_score_delivery'].apply(deliveryMap)\n",
    "    data['shop_map_description'] = data['shop_score_description'].apply(dspMap)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zuheFeature(data):\n",
    "    for col in ['item_sales_level', 'item_price_level', 'item_collected_level','item_pv_level',\n",
    "                'user_gender','user_age','user_occupation','user_star',\n",
    "                'shop_review_num_level', 'shop_star_level','shop_map_delivery','shop_map_service']:\n",
    "        data[col] = data[col].astype(str)\n",
    "\n",
    "    data['user_gender_age'] = data['user_gender'] + data['user_age']\n",
    "    data['user_gender_occ'] = data['user_gender'] + data['user_occupation']\n",
    "    data['user_gender_star'] = data['user_gender'] + data['user_star']\n",
    "    \n",
    "    data['shop_review_star'] = data['shop_review_num_level']+data['shop_star_level']\n",
    "    data['shop_delivery_service'] = data['shop_map_delivery'] + data['shop_map_service']\n",
    "    \n",
    "    data['item_collected_sales'] = data['item_sales_level'] + data['item_collected_level']\n",
    "    data['item_collected_pv'] = data['item_collected_level'] + data['item_pv_level']\n",
    "    data['item_sales_pv'] = data['item_sales_level'] + data['item_pv_level']\n",
    "    \n",
    "    for col in ['item_sales_level', 'item_price_level', 'item_collected_level','item_pv_level',\n",
    "                'user_gender','user_age','user_occupation','user_star',\n",
    "                'shop_review_num_level', 'shop_star_level','shop_map_delivery','shop_map_service',\n",
    "                'user_gender_age','user_gender_occ','user_gender_star',\n",
    "               'shop_review_star','shop_delivery_service',\n",
    "                'item_collected_sales','item_collected_pv','item_sales_pv']:\n",
    "        data[col] = data[col].astype(int)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 点击率统计特征\n",
    "def cntFeature(data, cols=['item_id','user_id','shop_id']):\n",
    "    # 今日之前的所有点击率\n",
    "    dmin = data['context_time_day'].min()\n",
    "    dmax = data['context_time_day'].max() + 1\n",
    "    for day in range(dmin, dmax):\n",
    "        df1 = data[data.context_time_day<day]\n",
    "        df2 = data[data.context_time_day==day]\n",
    "        for col in cols:\n",
    "            cnt = df1.groupby([col])['instance_id'].agg({'cnt':'count'})['cnt'].to_dict()\n",
    "            df2[str(col)+'_cnt'] = df2[col].apply(lambda x: cnt.get(x, 0))\n",
    "        df2 = df2[['item_id_cnt','user_id_cnt','shop_id_cnt','instance_id']]\n",
    "        if day == dmin:\n",
    "            rdf = df2\n",
    "        else:\n",
    "            rdf = pd.concat([df2,rdf])\n",
    "    data = pd.merge(data, rdf, on=['instance_id'],how='left')\n",
    "    return data\n",
    "\n",
    "def cnt1Feature(data, cols=['item_id','user_id','shop_id']):\n",
    "    # 今日之前一天的所有点击率\n",
    "    dmin = data['context_time_day'].min()\n",
    "    dmax = data['context_time_day'].max() + 1\n",
    "    for day in range(dmin, dmax):\n",
    "        df1 = data[data.context_time_day == (day-1)]\n",
    "        df2 = data[data.context_time_day == day]\n",
    "        for col in cols:\n",
    "            cnt = df1.groupby([col])['instance_id'].agg({'cnt':'count'})['cnt'].to_dict()\n",
    "            df2[str(col)+'_cnt1'] = df2[col].apply(lambda x: cnt.get(x, 0))\n",
    "        df2 = df2[['item_id_cnt1','user_id_cnt1','shop_id_cnt1','instance_id']]\n",
    "        if day == dmin:\n",
    "            rdf = df2\n",
    "        else:\n",
    "            rdf = pd.concat([df2,rdf])\n",
    "    data = pd.merge(data, rdf, on=['instance_id'],how='left')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————Start——————————\n",
      "——————————标签化——————————\n",
      "(495652, 58)\n",
      "——————————离散化——————————\n",
      "(495652, 63)\n",
      "——————————组合化——————————\n",
      "(495652, 71)\n",
      "——————————点击统计——————————\n",
      "(495652, 77)\n",
      "——————————END——————————\n"
     ]
    }
   ],
   "source": [
    "print (\"——————————Start——————————\")\n",
    "rows = df.shape[0]\n",
    "df1 = df.append(test_df)\n",
    "df1 = df1.drop_duplicates(subset='instance_id')  # 去除重复的instance_id\n",
    "df1 = dropCols(df1)\n",
    "\n",
    "print (\"——————————标签化——————————\")\n",
    "df_enc = dataLabelEncoder(df1)\n",
    "print (df_enc.shape)\n",
    "\n",
    "print (\"——————————离散化——————————\")\n",
    "df_enc = constantMap(df_enc)\n",
    "df_enc['shop_noraml'] = df_enc.apply(\n",
    "     lambda x : 1 if (x.shop_review_positive_map==3) and x.shop_map_service==3 and x.shop_map_delivery==3 and x.shop_map_description==3 else 0,\n",
    "     axis=1)\n",
    "print (df_enc.shape)\n",
    "\n",
    "print (\"——————————组合化——————————\")\n",
    "df_zuhe = zuheFeature(df_enc)\n",
    "print (df_zuhe.shape)\n",
    "\n",
    "print (\"——————————点击统计——————————\")\n",
    "df_cnt1 = cnt1Feature(df_zuhe)\n",
    "df_cnt = cntFeature(df_cnt1)\n",
    "print (df_cnt.shape)\n",
    "\n",
    "print (\"——————————END——————————\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = pd.DataFrame({'is_trade':label})\n",
    "test_df = df_cnt[df_cnt.is_trade.isnull()]\n",
    "df = df_cnt[df_cnt.is_trade.notnull()]\n",
    "# del df_enc, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477284, 77)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理完毕，保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../Output/a/train_step3_301_final.csv', index=False)\n",
    "test_df.to_csv('../Output/a/test_step3_301_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
